[
["index.html", "연구데이터 분석과정 (R프로그래밍) Chapter 1 Introduction 강의 개요 1.1 References books 참고 교제 1.2 References 참고 자료 1.3 Schedule 강의 계획", " 연구데이터 분석과정 (R프로그래밍) 한국생명공학연구원 김하성 2020-10-16 Chapter 1 Introduction 강의 개요 장소: 코빅 3층 전산교육장(1304호) 강사: 한국생명공학연구원 바이오합성연구센터 김하성 연락처: 042-860-4372, haseong@kribb.re.kr (생명연 연구동 1143) 강의자료: https://greendaygh.github.io/KRIBBR2020/ 1.1 References books 참고 교제 Using R for Introductory Statistics by John Verzani Free version of 1st Edition https://cran.r-project.org/doc/contrib/Verzani-SimpleR.pdf Second edition https://www.crcpress.com/Using-R-for-Introductory-Statistics-Second-Edition/Verzani/p/book/9781466590731 R for Data Science (https://r4ds.had.co.nz, https://github.com/hadley) Bioinformatics Data Skills by Vince Buffalo (http://2.droppdf.com/files/5aTvl/bioinformatics-data-skills.pdf) First Course in Statistical Programming with R by Braun and Murdoch (https://www.cambridge.org/core/books/first-course-in-statistical-programming-with-r/C9F088122AB40517B07FA77F2F0FDE2F) Introductory Statistics with R by Dalgaard (http://www.academia.dk/BiologiskAntropologi/Epidemiologi/PDF/Introductory_Statistics_with_R__2nd_ed.pdf) Modern Applied Statistics with S by Venables and Ripley (http://www.bagualu.net/wordpress/wp-content/uploads/2015/10/Modern_Applied_Statistics_With_S.pdf) 일반통계학 (영지문화사, 김우철 외) 1.2 References 참고 자료 R 홈페이지 https://www.r-project.org/ Rstudio 홈페이지 https://www.rstudio.com/ Packages for biologists https://www.bioconductor.org/ R 기본 문서들 (소개, 사용, 설치, 운영) https://cran.r-project.org/manuals.html R ebooks https://bookdown.org/ Cheat Sheets https://www.rstudio.com/resources/cheatsheets/ https://resources.rstudio.com/ http://shiny.rstudio.com/tutorial/ 1.3 Schedule 강의 계획 Day1 - R/Rstudio/Statistics/Sequence basics Day2 - Bioconductor Day3 - dplyr and ggplot2 Day4 - Case study "],
["rrstudio-basics.html", "Chapter 2 R/Rstudio basics 2.1 What is R / Rstudio 2.2 R / Rstudio installation 2.3 Rstudio interface 2.4 R coding practice 2.5 Supports 2.6 R packages and Dataset", " Chapter 2 R/Rstudio basics 2.1 What is R / Rstudio R은 통계나 생물통계, 유전학을 연구하는 사람들 사이에서 널리 사용되는 오픈소스 프로그래밍 언어 입니다. Bell Lab에서 개발한 S 언어에서 유래했으며 엄청나게 많은 라이브러리 (다른 사람들이 만들어 놓은 코드)가 있어서 쉽게 가져다 사용할 수 있습니다. R은 복잡한 수식이나 통계 알고리즘을 간단히 구현하고 사용할 수 있으며 C, C++, Python 등 다른 언어들과의 병행 사용도 가능합니다. 2019년 top five language에 랭크 되었으며 이는 빅데이터 증가에 따라 인기가 높아진 것으로 볼 수 있습니다 (참고로 2018년에는 7위). Despite being a much more specialized language than the others, it’s maintained its popularity in recent years due to the world being awash in an ever-growing pile of big data. https://spectrum.ieee.org/computing/software/the-top-programming-languages-2019 R은 통계분석에 널리 사용되는데 이는 데이터 가시화를 위한 그래픽 기능이나 벡터 연산 등의 편리함 때문에 점점 더 많은 사람들이 사용하고 있습니다. 기존에는 느린 속도나 부족한 확장성이 다른 언어들에 비해 단점으로 지적되었으나 R 언어의 계속적인 개발과 업데이트로 이러한 단점들이 빠르게 극복되고 있습니다. R 사용을 위해서는 R 언어의 코어 프로그램을 먼저 설치하고 그 다음 R 언어용 IDE인 RStudio 설치가 필요합니다. 2.2 R / Rstudio installation 2.2.1 R 설치 R 사이트에 접속 후 (https://www.r-project.org/) 좌측 메뉴 상단에 위치한 CRAN 클릭. 미러 사이트 목록에서 Korea의 아무 사이트나 들어감 Download R for Windows를 클릭 후 base 링크 들어가서 Download R x.x.x for Windows 링크 클릭으로 실행 프로그램 다운로드 - 로컬 컴퓨터에 Download 된 R-x.x.x-win.exe 를 실행 설치 가이드에 따라 R 언어 소프트웨어 설치 완료 2.2.2 Rstudio 설치 Rstudio는 R 언어를 위한 오픈소스 기반 통합개발환경(IDE)으로 R 프로그래밍을 위한 편리한 기능들을 제공해 줍니다. 사이트에 접속 (https://www.rstudio.com/), 상단의 Products &gt; RStudio 클릭 RStudio Desktop 선택 Download RStudio Desktop 클릭 RStudio Desktop Free 버전의 Download를 선택하고 Download RStudio for Windows 클릭, 다운로드 로컬 컴퓨터에 다운로드된 RStudio-x.x.x.exe 실행 설치 가이드에 따라 설치 완료 2.3 Rstudio interface 좌측 상단의 공간은 코드편집창, 좌측 하단은 콘솔창 이며 각 위치를 기호에 따라서 바꿀 수 있습니다. 2.3.1 Keyboard shortcuts 참고사이트 https://support.rstudio.com/hc/en-us/articles/200711853-Keyboard-Shortcuts Tools –&gt; Keyboard shortcut Quick Reference (Alt + Shift + K) 코드편집창 이동 (Ctrl+1) 콘솔창 이동(Ctrl+2) 한 줄 실행 (Ctrl+Enter) 주석처리 (Ctrl + Shift + C) 또는 #으로 시작하는 라인 실습 코드편집창에서 다음 입력 단축키 Ctrl + enter로 코드 실행 단축키 Ctrl + 2로 커서 콘솔창으로 이동 x값 x+y값 확인 단축키 Ctrl + 1로 코드편집창 이동 단축키 Ctrl + Shift + C 사용 # x &lt;- 10 # y &lt;- 20 2.3.2 Set a working directory 시작 전 항상 작업 디렉토리 설정하는 것이 좋습니다. 예를 들어 c:\\ 아래 새로운 디렉토리 kribb-r 을 만들고 작업공간으로 설정할 수 있습니다. getwd() dir() setwd(&quot;C:\\\\kribb-r&quot;) getwd() dir() 또는 RStudio &gt; Session &gt; Set Working Directory &gt; Choose Directory 2.3.3 Set a project 프로젝트를 만들어서 사용할 경우 파일이나 디렉토리, 내용 등을 쉽게 구분하여 사용 가능합니다. 아래와 같이 원하는 위치에 원하는 이름의 프로젝트를 생성하고 프로젝트를 시작할 때는 해당 디렉토리의 xxx.Rproj 파일을 클릭합니다. File &gt; New Project &gt; New Directory &gt; New Project &gt; “kribb-R” &gt; Create Project File &gt; New File &gt; R Script &gt; “day1.R” 2.4 R coding practice 2.4.1 Console calculator 2 + 2 ((2 – 1)^2 + (1 – 3)^2 )^(1/2) 2 + 2; 2 - 2 2.4.1.1 Exercise 다음 공식들을 계산하는 R 코드를 작성하시오 \\[ \\sqrt{(4+3)(2+1)} \\] \\[ 2^3 + 3^2 \\] \\[ \\frac{0.25 - 0.2}{\\sqrt{0.2 (1-0.2)/100}}\\] 2.4.2 Variables and values 프로그래밍 언어의 공통적 개념 변수, 함수, 자료형, 조건문, 반복문 Assignment operator ( &lt;- OR = ) Valid object name &lt;- value 단축키: Alt + - (the minus sign) x &lt;- 2 y &lt;- x^2 – 2*x + 1 y x &lt;- &quot;two&quot; some_data &lt;- 9.8 내장 변수 Built-in variables pi 변수이름 작명법 문자, 숫자, “_”, “.” 등으로 구성 대소문자 구분 가독성, 의미있는 변수 이름 길이 제한 없음 i_use_snake_case &lt;- 1 otherPeopleUseCamelCase &lt;- 2 some.people.use.periods &lt;- 3 And_aFew.People_RENOUNCEconvention &lt;- 4 자동 완성 기능 (Tab completion) in RStudio 이전 명령은 콘솔에서 위 아래 화살표 내장 함수 (Built-in functions) x &lt;- pi sin(x) sqrt(x) log(x) log(x, 10) x &lt;- c(10, 20, 30) x + x mean(x) sum(x)/length(x) 2.4.2.1 Exercise 변수 x에 1, 3, 5, 7, 9를, 변수 y에 2, 4, 6, 8, 10을 저장하는 코드를 작성하고 x와 y를 더한 값을 z에 저장하는 코드를 작성하시오 2.5 Supports 2.5.1 Help help(&quot;mean&quot;) ?mean example(&quot;mean&quot;) help.search(&quot;mean&quot;) ??mean help(package=&quot;MASS&quot;) 2.5.2 Cheatsheet https://rstudio.com/resources/cheatsheets/ 2.6 R packages and Dataset 2.6.1 R packages R 패키지는 함수들의 모음으로 다른 사람들이 만들어 놓은 함수를 가져와서 사용할 수 있음 예) sum() 은 base package에 있고 sd() 함수는 stats package에서 제공 패키지를 구할 수 있는 가장 대표적인 사이트 The Comprehensive R Archive Network (CRAN) - http://cran.r-project.org/web/views/ Bioconductor - http://www.bioconductor.org/packages/release/bioc/ UsingR package installation install.packages(&quot;UsingR&quot;) UsingR package loading library(UsingR) help(package=&quot;UsingR&quot;) 2.6.2 Data sets 일반적으로 패키지 안에 관련된 데이터도 같이 저장 data() function를 이용해서 패키지 데이터를 사용자 작업공간에 복사해서 사용 가능 head(rivers) length(rivers) class(rivers) data(rivers) data(package=&quot;UsingR&quot;) library(HistData) head(Cavendish) str(Cavendish) head(Cavendish$density2) 이 저작물은 크리에이티브 커먼즈 저작자표시-비영리-변경금지 4.0 국제 라이선스에 따라 이용할 수 있습니다. "],
["basic-statistics.html", "Chapter 3 Basic Statistics 3.1 Univariat data 3.2 Bivariate data", " Chapter 3 Basic Statistics 3.1 Univariat data Statistics: 데이터 분석을 통한 예측. 즉, 데이터를 수집, 정리하여 이로부터 미지의 사실에 대한 신빙성 있는 추론을 수행하는 과정 Univariate (단변량): Single variable \\[ x_1, x_2, ..., x_n \\] x &lt;- c(1, 2, 3, 4, 5) length(x) 데이터의 속성에 따른 구분 범주형 - 질적 데이터, 숫자로 나타낼 수 있으나 의미 없음 명목형 (Nominal) - 사람 이름 순서형 (Ordinal) – 달리기 도착 순서 수치형 - 숫자로 나타내며 데이터 속성을 그대로 지님님 구간형 (Interval) – 선수1, 선수2 종점통과 시간 비율형 (Ratio) – 출발시간 기준 종점 통과 시간 Data type in R Numeric data types (수치형) Discrete (이산형) data - 카운트, 횟수 Continuous (연속형) data - 키, 몸무게, Cannot be shared Factors data - 혈액형, 지역 (범주형) Character data - ID, 이름 (범주형) Logical data - 참, 거짓 (논리형) 3.1.1 Vectors for univariate data Using combine function #The number of whale beachings in Texas during the 1990s whale &lt;- c(74, 122, 235, 111, 292, 111, 211, 133, 156, 79) #Object `whale` is a data vector == (univariate) data set # The size length(whale) sum(whale) sum(whale)/length(whale) mean(whale) Vectorization whale - mean(whale) whale^2 - mean(whale) sqrt(whale) Adding values to a vector variable x &lt;- 1 x &lt;- c(x, 2) x x &lt;- c(x, 3, 3, 3, 4) x Missing/NULL values NA: Not available, The value is missing NULL: a reserved value NaN: Not a number (0/0) Inf: (1/0) hip_cost &lt;- c(10500, 45000, 74100, NA, 83500) sum(hip_cost) sum(hip_cost, na.rm=TRUE) ?sum Attributes: names in data vectors head(precip) class(precip) length(precip) names(precip) order(names(precip)) test_scores &lt;- c(100, 90, 80) names(test_scores) &lt;- c(&quot;Alice&quot;, &quot;Bob&quot;, &quot;Shirley&quot;) Indexing head(precip) precip[1] precip[2:10] precip[c(1,3,5)] precip[-1] precip[&quot;Seattle Tacoma&quot;] precip[c(&quot;Seattle Tacoma&quot;, &quot;Portland&quot;)] precip[2] &lt;- 10 3.1.2 Storage data type Numeric data class(1) class(pi) x &lt;- seq(1,5,by=1) class(x) seq(0, 100, by=10) seq(0, 100, length.out=11) ?seq rep(5, times10) rep(1:3, times=4) Character data ch &lt;- c(&quot;Lincoln&quot;, &quot;said&quot;, &quot;and&quot;) class(ch) 3.1.2.1 Exercise seq 또는 rep 함수를 사용해서 다음 서열들을 만들고 x 변수에 저장하시오 “a”, “a”, “a”, “a”, “a” 1, 3, 5, 7, …, 99 1, 1, 1, 2, 2, 2, 3, 3, 3 1, 2, 3, 4, 5, 4, 3, 2, 1 Combining strings - paste function paste(&quot;X&quot;, 1:10) paste(&quot;X&quot;, 1:10, sep=&quot;&quot;) paste(&quot;The&quot;, &quot;quick&quot;, &quot;brown&quot;, &quot;fox&quot;) paste(c(&quot;The&quot;, &quot;quick&quot;, &quot;brown&quot;, &quot;fox&quot;)) paste(c(&quot;The&quot;, &quot;quick&quot;, &quot;brown&quot;, &quot;fox&quot;), collapse=&quot; &quot;) x &lt;- 1:10 paste(x) paste(x, collapse=&quot;:&quot;) Factors x &lt;- c(&quot;Red&quot;, &quot;Blue&quot;, &quot;Yellow&quot;, &quot;Green&quot;, &quot;Blue&quot;, &quot;Green&quot;) y &lt;- factor(x) y Adding a level levels(y) y[1] &lt;- &quot;Gold&quot; y levels(y) &lt;- c(levels(y), &quot;Gold&quot;) levels(y) y y[1] &lt;- &quot;Gold&quot; y Logical data * TRUE and FALSE * “is” functions * Comparison by &lt;, &lt;=, ==, !=, &gt;=, &gt; * Combination by !, &amp;, | is.na(1) is.numeric(1) is.logical(TRUE) pi &lt; 3 precip &lt; 30 which(precip &lt; 30) any(precip &lt; 30) all(precip &lt; 30) any(39 == precip) which(39 == precip) sum(precip &lt; 30) sum(c(TRUE, TRUE)) x &lt;- 1:100 x &lt; 10 x &gt; 90 x &lt; 10 | x &gt;90 which(x &lt; 10 | x &gt;90) i &lt;- which(x &lt; 10 | x &gt;90) x[i] x[x &lt; 10 | x &gt;90] 3.1.2.2 Exercise 다음은 신생아들의 키를 나타내는 dataset 이다. 오류 값을 찾아내고 이들 값을 NA로 바꾼 후 평균 값을 구하시오 (babies 데이터셋은 UsingR 패키지에 있으며 오류값은 999 입니다) x &lt;- babies$dwt x 3.1.2.3 Exercise 특정 숫자가 짝수인지를 검사하는 방법은 해당 숫자를 2로 나누어 나머지가 0인지 확인하는 방법이다. 2 %% 2 == 0 위와 같은 코드로 이를 구현할 수 있다. 다음 변수의 값들 중 짝수의 개수를 구하는 코드를 작성하시오 (1줄 코드임). x &lt;- c(12, 3, 4, 2, 28, 11, 8, 9, 51, 89) 3.1.3 Use of functions Function 정의 my_sine &lt;- function(x){ y &lt;- sin(x) return(y) } 사용법 my_sine(pi) 용어 function name: my_sine parameter: x argument: pi return value: y 평균 계산하는 함수 my_mean head(rivers) my_mean &lt;- function(x){ total &lt;- sum(x) n &lt;- length(x) return(total/n) } my_mean(rivers) 3.1.3.1 Exercise 평균과의 거리를 계산하는 get_dist 함수를 작성하고 rivers 데이터에 사용하시오 get_dist &lt;- function(x){ return() } get_dist(rivers) 3.1.3.2 Exercise 강수량 데이터 precip에서 연평균 강수량이 50 이상인 도시를 뽑고 해당 도시들의 강수량에 따라서 순서대로 나열하시오 3.1.4 Numeric summaries 대푯값 (요약값) Center – commonly known as “average” or “mean” but not the only one. median, mode, etc Spread – Variability of a data set. No variability – mean is everything Large variability – mean informs much less confidence of interpretation from knowing center Distance from center Shape – Degree of interpretation from knowing center and spread. eg. bell shape – two sides are equally likely, large values are rather unlikely and values tend to cluster near the center. 3.1.5 Center for a univariat variable 3.1.5.1 Sample mean \\[ \\bar{x} = \\frac{1}{n} (x_1 + x_2 + ... + x_n) = \\frac{1}{n}\\sum_i{x_i} \\] length(rivers) plot(rivers) mean(rivers) devs &lt;- rivers - mean(rivers) plot(devs) mean(devs) Robustness mean(devs) median(devs) plot(devs) abline(h=mean(devs), col=&quot;red&quot;) abline(h=median(devs), col=&quot;blue&quot;) devs &lt;- devs[devs&lt;1500] abline(h=mean(devs), col=&quot;red&quot;, lty=2) abline(h=median(devs), col=&quot;blue&quot;, lty=2) 3.1.6 Spread for a univariat variable Range - the distance between the smallest and largest values Sample variance \\[\\begin{equation} s^2 = \\frac{1}{n-1}\\sum_i(x_i - \\bar{x})^2 \\end{equation}\\] Sample standard deviation 측정값들이 평균에서 떨어진 정도 \\[\\begin{equation} \\sqrt{s^2} = \\sqrt{ \\frac{1}{n-1}\\sum_i(x_i - \\bar{x})^2 } \\end{equation}\\] library(UsingR) wts &lt;- kid.weights$weight var(wts) sd(wts) plot(wts) boxplot(wts) hist(wts) hist(wts, breaks = 50) hist(wts, 50) abline(v=mean(wts), col=&quot;red&quot;) Interquartile range (IQR) Middle 50% of the data Difference between Q3 and Q1 3.1.7 Shape for a univariat variable Symmetry and skew \\[\\begin{equation} \\text{sample skewness} = \\sqrt{n} \\frac{\\sum{(x_i - \\bar{x})^2}}{(\\sum{(x_i - \\bar{x})^2)^{3/2}}} = \\frac{1}{n}\\sum{z_i^3} \\end{equation}\\] myskew &lt;- function(x){ n &lt;- length(x) z &lt;- (x-mean(x))/sd(x) return(sum(z^3)/n) } wts &lt;- kid.weights$weight hist(wts, 50) myskew(wts) z &lt;- rnorm(length(wts)) hist(z, br=50) myskew(z) Sample excess kurtosis Measure of tails \\[\\begin{equation} \\text{sample excess kurtosis} = n \\frac{\\sum{(x_i - \\bar{x})^4}}{(\\sum{(x_i - \\bar{x})^2)^2}} -3 = \\frac{1}{n}\\sum{z_i^4} - 3 \\end{equation}\\] mykurtosis &lt;- function(x){ n &lt;- length(x) z &lt;- (x-mean(x))/sd(x) return(sum(z^4)/n - 3) } wts &lt;- kid.weights$weight hist(wts, 50) mykurtosis(wts) z &lt;- rnorm(length(wts)) hist(z, br=50) mykurtosis(z) 3.1.8 Viewing the shape 3.1.8.1 Histogram 도수분포표를 나타낸 그림으로 데이터를 특정 범위의 그룹으로 짝짓고 해당 범위와 그룹의 크기에 해당하는 막대를 그린 그래프입니다. library(UsingR) x &lt;- faithful$waiting hist(x) hist(x, breaks = 1000) hist(x, breaks = 20, freq=FALSE) hist(x, breaks = 20, freq=FALSE, main=&quot;Histogram&quot;) hist(x, breaks = 20, freq=FALSE, main=&quot;Histogram&quot;, xlim=c(0, 100)) hist(x, breaks = 20, freq=FALSE, main=&quot;Histogram&quot;, xlim=c(0, 100), ylim=c(0, 0.1)) 히스토그램은 center (mean, median), spread (Variance, IQR), shape (tail)을 모두 볼 수 있는 그래프입니다. 그리는 방법은 전체 범위의 데이터가 포함되도록 범위를 정하고 동일 같격으로 구분되는 계급의 개수를 정한 후 해당 계급에 속하는 데이터의 개수를 세어 도수를 구합니다. 다음은 도수 분포표를 만드는 코드 입니다. x &lt;- faithful$waiting bins &lt;- seq(40, 100, by=5) out &lt;- cut(x, breaks=bins) table(out) plot(table(out)) 3.1.8.2 Density plots 히스토그램을 갖는 하나의 단변량 변수가 있을 때 특정 값이 선택될 확률은 히스토그램의 해당 계급의 도수값을 전체로 나눈 값이라고 할 수 있습니다. 그런나 연속적인 구간이나 시간의 경우에는 히스토그램보다는 density plot이 요약값을 보기에 더 적합합니다. wts &lt;- kid.weights$weight xrange &lt;- range(wts) den &lt;- density(wts) plot(den, xlim=xrange, xlab=&quot;densities&quot;, main=&quot;&quot;) 3.1.8.3 Boxplots 상자그림 또는 상자 수염 그림으로 불리는 boxplot은 다섯개의 주요 요약값을 (min, max, Q1, Q3, and median) 보여주며 대규모 데이터를 한 눈에 비교할 수 있는 좋은 방법 입니다. Boxplot x &lt;- 0:5 quantile(x) boxplot(x) text(x=1.3, y=quantile(x, 0.25), labels = &quot;1사분위수&quot;) text(x=1.3, y=quantile(x, 0.5), labels = &quot;2사분위수&quot;) text(x=1.3, y=quantile(x, 0.75), labels = &quot;3사분위수&quot;) boxplot(kid.weights) boxplot(kid.weights$weight) #install.packages(&quot;vioplot&quot;) library(vioplot) vioplot(kid.weights) vioplot(kid.weights, col=c(&quot;#3CAEA3&quot;, &quot;#F6D55C&quot;, &quot;#ED553B&quot;), rectCol=c(&quot;gray&quot;), main=&quot;Kids&quot;) ?vioplot #console par(mfrow=c(1,2)) plot(density(kid.weights$weight)) vioplot(kid.weights$weight) 3.1.8.4 Exercise 다음 데이터를 age 변수에 저장하고 mean, median, variance 를 구하시오. 또한 age의 boxplot을 그리고 중간값을 출력하시오 {7, 9, 2, 64, 41, 60, 82, 31, 38, 25, 52, 68, 67} 3.2 Bivariate data 두 변수를 동시에 고려할 경우 각 변수가 가지고 있는 데이터를 비교하여 변수간의 유사성이나 관계 (상관, 독립)에 대한 설명하는 방법을 소개하며 짝데이터 (Paired data)나 범주형 데이터의 경우에 두 변수의 관계를 어떻게 설명하는지 알아봅니다. 또한 그래프를 이용하여 두 변수의 관계를 가시화 하는 방법에 대해 알아보겠습니다. 3.2.1 Independence samples 두 변수간의 관계를 설명할 때 가장 일반적인 경우의 데이터 형태는 코흐트 데이터 입니다. 처리군과 대조군으로 이루어진 데이터를 말하며 플라시보 (Placebo effect) 효과를 방지하기 위해서 실제 효과는 없지만 대조군에 처리한 조건과 동일한 조건의 처리를 수행합니다. beets &lt;- c(41, 40, 41, 42, 44, 35, 41, 36, 47, 45) no_beets &lt;- c(51, 51, 50, 42, 40, 31, 43, 45) 위 데이터는 비트의 효과를 검증하기 위해 각 실험자의 달리는 시간을 측정하고 비교한 데이터 입니다. 이 데이터를 보고 알 수 있는 사실은 무엇입니까? 3.2.2 Data comparison with plots 두 변수에 대한 관계를 가장 먼저 그리고 가장 직관적으로 설명하는 방법은 그래프 입니다. boxplot에서는 앞에서 배운바와 같이 다섯 가지 요약값을 볼 수 있습니다. 1사분위수, 2사분위수(중간값), 3사분위수, 그리고 최대, 최소값입니다. 여기서 최대 최소는 3사분위수 또는 1사분위수에서 IQR 1.5배에 해당하는 하위 또는 상위 값으로 그 범위를 벗어나는 값들은 outlier로 취급합니다. boxplot(beets, no_beets) boxplot(beets, no_beets, names=c(&quot;beets&quot;, &quot;no_beets&quot;)) Density plot은 histogram과 비슷하게 데이터의 center, spread, 그리고 shape를 모두 보여주는 높은 활용도 때문에 많이 사용되는 그래프 입니다. density 함수는 밀도함수를 추정하고 주어진 범위의 x값과 그에 대한 y값을 반환해주며 plot 함수를 이용하여 x와 y위치에 점이나 선을 그려주어 그래프를 완성합니다. library(UsingR) head(michelson) ?michelson str(michelson) speed &lt;- michelson$Speed expt &lt;- michelson$Expt fourth &lt;- speed[expt == 4] fifth &lt;- speed[expt == 5] d4 &lt;- density(fourth) d5 &lt;- density(fifth) xrange &lt;- range(c(d4$x, d5$x)) yrange &lt;- range(c(d4$y, d5$y)) plot(d4, xlim=xrange, ylim=yrange, main=&quot;&quot;) lines(d5, lty=2) legend(650, 0.008, legend=c(&quot;Fourth&quot;, &quot;Fifth&quot;), lty=c(1,2)) plot(fourth, fifth) 3.2.3 Data manipulation 3.2.3.1 List R언어에서 두 변수를 담을 수 있는 데이터 타입은 list와 data frame 두 종류가 있습니다. list 변수 타입은 vector 형태의 여러개의 element를 가질 수 있으며 각 element의 데이터는 문자나 숫자 어떤 데이터 타입도 가능하며 각 element vector의 길이가 모두 달라도 됩니다. list의 인덱싱에서 [ ]는 리스트를 반환하고 [[ ]]는 vector element들을 반환합니다. b &lt;- list(beets = beets, &quot;no beets&quot;=no_beets) b$beets b[1] b[[1]] class(b[1]) class(b[[1]]) boxplot(b) 3.2.3.2 Exercise 다음 데이터를 list 타입의 변수, record에 저장하고 boxplot을 이용해서 비교하시오 marsha: 25, 0, 45, 90, 0, 10, 60, 25 bill: 30, 30, 30, 30, 20, 10, 15, 20 3.2.3.3 Matrices 메트릭스는 같은 타입의 데이터로 채워진 사각형 모양을 갖는 컨테이너로 볼 수 있습니다. 인덱스는 [i, j] 형태로 i는 row, j는 column 을 가리킵니다. 메트릭스의 생성은 matrix 명령어를 사용하며 다음과 같이 각 column 별로 값을 채워 나가는 것이 기본 설정이며 byrow=T 를 통해 row를 다 채우고 그 다음 row를 채워 나가게 할 수도 있습니다. mymat &lt;- matrix(0, nrow=100, ncol=3) # 1 mymat[,1] &lt;- 1:100 # 2 mymat[,2] &lt;- seq(1,200,2) # 3 mymat[,3] &lt;- seq(2,200,2) # 4 m &lt;- matrix(c(1,2,3,4), nrow=2) m m &lt;- matrix(c(1,2,3,4), nrow=2, byrow = T) m row와 column 이름은 rownames와 colnames로 설정이 가능하며 rbind와 cbind는 벡터를 연결하고 붙이는 역할을 할 수 있으나 데이터가 많거나 반복해서 수행할 경우 컴퓨터의 리소스를 많이 사용하는 문제로 느려질 수 있습니다. m &lt;- cbind(1:3, c(1.1, 1.2, 1.3), c(1, 1, 2)) # a 3 by 3 matrix colnames(m) &lt;- c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;) # or cbind(x=..., ...) m dim(m) 3.2.3.4 Data frame data.frame 타입 변수는 list와 같은 기능의 타입으로 볼 수 있지만 모든 element 들이 같은 길이를 갖는다는 것이 다릅니다. 따라서 2차원 메트릭스 형태로 표현될 수 있으며 matrix와 같이 [가로, 세로] 방식으로 인덱싱 할 수 있습니다. 각 row는 샘플을 나타내고 column은 하나의 변수를 타나냅니다. R 기반의 데이터 분석에서는 가장 선호되는 데이터 타입이라고 볼 수 있습니다. id &lt;- 1:10 name &lt;- paste(&quot;Name&quot;, id, sep=&quot;&quot;) grade &lt;- LETTERS[sample(1:5, size=length(id), replace=T)] student &lt;- data.frame(id, name, grade) student str(student) student$id student[,1] class(student$name) class(student) class(student[,1]) class(student$id) student &lt;- data.frame(id, name, grade, stringsAsFactors = F) str(student) ?data.frame 3.2.3.5 Model formulas R에서는 두 개 (이상의) 변수의 관계를 수학적으로 표현하기 위한 방법을 제공하며 다양한 모형에서 공통적으로 사용될 수 있습니다. \\[ response(s) \\sim predictor(s) \\] beets no_beets runtime &lt;- c(beets, no_beets) nitrate &lt;- c(rep(&quot;beets&quot;, length(beets)), rep(&quot;nobeets&quot;, length(no_beets))) food.sports &lt;- data.frame(runtime, nitrate) boxplot(runtime~nitrate, data=food.sports) head(michelson) boxplot(michelson$Speed ~ michelson$Expt) boxplot(Speed ~ Expt, data=michelson) R에서 plot함수는 Generic function으로서 입력 파라메터가 갖는 데이터 타입에 따라서 다른 기능을 수행할 수 있습니다. 예를 들어 formula type으로 \\(x \\sim f\\) 가 들어갈 경우 그룹별로 boxplot을 나란히 그려주며 따라서 그룹별로 데이터가 얼마나 다른지 한 눈에 비교할 수 있습니다. plot(Speed ~ Expt, data=michelson) out &lt;- summary(Speed ~ Expt, data=michelson) plot(out) plot(michelson$Speed) plot(michelson$Speed, main=&quot;Speed&quot;, ylab=&quot;Speed&quot;, bty=&quot;l&quot;, pch=&quot;*&quot;, cex=2, col=&quot;red&quot;) ?pch split 함수의 경우 data를 정의된 그룹으로 나누고 list 타입으로 반환해줍니다. 그룹은 factor 형으로 정의된 변수에 저장되어 있어야 합니다. ?split speeds &lt;- split(michelson$Speed, michelson$Expt) names(speeds) &lt;- paste(&quot;Expt&quot;, 1:5, sep=&quot;&quot;) speeds speed &lt;- michelson$Speed expt &lt;- michelson$Expt speed expt speeds &lt;- list(speed[expt==1], speed[expt==2], speed[expt==3], speed[expt==4], speed[expt==5]) names(speeds) &lt;- paste(&quot;Expt&quot;, 1:5, sep=&quot;&quot;) speeds 3.2.4 Paired data paired data는 두 종류의 변수에 대한 데이터를 하나의 샘플로 부터 얻을 때의 데이터를 말합니다. 본 단원에서 두 변수의 데이터형은 연속형과 연속형, 또는 연속형과 범주형의 경우로 다음 단원에서 범주형과 범주형에 대한 경우의 두 변수간 관계를 설명하겠습니다. 예를 들어 한 학생으로부터 얻어진 키와 몸무게 데이터가 paired data가 될 수 있습니다. paired data는 보통 다음과 같은 형태를 취하고 있습니다. \\[ (x_1, y_1), (x_2, y_2), ..., (x_{252}, y_{252}) \\] 걸리버 여행기라는 (1726) 소설이 나올 무렵의 사람들은 손목과 목, 허리 둘래가 항상 일정 비율로 비례하는 것을 알고 있었는데 이를 Lilliputians’ hypothesis라고 합니다. 이를 fat 데이터를 통해 알아 봅니다. UsingR 패키지의 fat 데이터는 252명의 남성으로부터 얻어진 다른 신체 부위의 측정 값을 제공하고 있으며 fat index를 예측하기 위한 목적으로 사용될 수 있습니다. 본 강의에서는 neck과 wrist 두 변수간의 관계를 설명하기 위한 데이터로 사용됩니다. library(UsingR) class(fat) head(fat) names(fat) neck_pair &lt;- fat$neck wrist_pair &lt;- fat$wrist mean(neck_pair/wrist_pair) mean(neck_pair)/mean(wrist_pair) plot(neck_pair, wrist_pair) 손목과 목 둘레를 측정한 데이터의 대표값 (평군)을 이용하여 두 변수 사이의 비율을 계산해 보면 2.084로 거의 두 배의 비율을 보입니다. 짝 데이터가 아닌 경우의 비율은 어떻게 될지 계산해 보면 아래와 같이 2.08로 비슷한 값이 구해집니다. 그러나 plot을 사용해서 산점도를 그려보면 nopair 데이터의 경우 두 변수의 상관성이 사라지는 것을 알 수 있습니다. 이것이 의미하는 바는 같은 사람에게서 얻은 짝데이터로만 손목과 목둘래가 비례한다는 정보를 알 수 있다는 것 입니다. 즉, 아무리 평균으로 2배의 차이가 있다고 할지라도 짝데이터 없이는 손목 둘래가 큰 사람이 목 둘래도 크다라고 말할 수 없다는 것 입니다. neck_nopair &lt;-sample(fat$neck) wrist_nopair &lt;- sample(fat$wrist) mean(neck_nopair)/mean(wrist_nopair) mean(neck_nopair/wrist_nopair) plot(neck_nopair, wrist_nopair) 3.2.4.1 Pearson Correlation 상관 또는 상관계수는 두 변수의 선형적 관계를 정량적으로 나타내는 척도입니다. 상관계수의 값이 0일 경우 두 변수는 독립 (independence)이라고 할 수 있고 선형 관계에 대해서만 사용됩니다. x &lt;- fat$wrist y &lt;- fat$neck plot(x, y) abline(v = mean(x), lty=2) abline(h = mean(y), lty=2) points(mean(x), mean(y), pch=16, cex=4, col=&quot;#00000055&quot;) abline(lm(y~x)) 공분산 (covariance)와 상관 (correlation)은 데이터의 중앙을 기준으로 4개의 구역에 각 데이터가 흩어진 정도를 정량화 한 것이며 다음과 같이 정의됩니다. \\[ cov(x, y) = \\frac{1}{n-1} \\sum{(x_i-\\bar{x})(y_i-\\bar{y})} \\] \\[ cor(x, y) = \\frac{1}{n-1} \\sum{(\\frac{x_i-\\bar{x}}{s_x})(\\frac{y_i-\\bar{y}}{s_y})} = cov(x,y)/(s_x s_y)\\] cor(fat$wrist, fat$neck) cor(fat$wrist, fat$height) cor(fat$age, fat$ankle) 3.2.4.2 Spearman correlation coefficient 피어슨 상관계수는 선형적 관계에 대한 정량화만 가능한 반면 spearman 상관계수는 선형관계 뿐만 아니라 비선형 적인 관계에 대해서도 단조 증가나 감소에 대한 정보를 측정할 수 있는 measure 입니다. 이는 데이터의 값 자체를 사용하기 보다는 데이터를 rank 값으로 변환한 후 상관성을 비교하기 때문에 가능한 기능입니다. from wiki x &lt;- Animals$body y &lt;- Animals$brain cor(x, y) plot(x, y) Animals cor(rank(x), rank(y)) cor(x, y, method=&quot;spearman&quot;) Animals 데이터에서 correlation 값이 낮은 이유는 공룡과 같이 뇌 무게에 비해 비정상적으로 큰 몸무게 값을 갖는 개체들 때문입니다. Example: 공룡을 제외한 correlation을 구하시오 일반적으로 분석의 신뢰성을 높이기 위해 실험 반복을 통해 데이터를 수집합니다. 그런데 가끔은 전체 반복 데이터를 모두 사용해서 상관계수를 구하는 값보다 각 반복 데이터의 평균에 대한 상관 계수를 구랗 때 더 높은 상관 관계를 확인할 수 있습니다. ToothGrowth plot(ToothGrowth$dose, ToothGrowth$len) cor(ToothGrowth$dose, ToothGrowth$len) l &lt;- split(ToothGrowth$len, ToothGrowth$dose) group_means &lt;- c(mean(l[[1]]), mean(l[[2]]), mean(l[[3]])) points(c(0.5, 1, 2), group_means, col=&quot;red&quot;, pch=17, cex=2) cor(c(0.5, 1, 2), group_means) 3.2.4.3 Exercise UsingR 패키지의 fat에는 체지방 데이터와 BMI 스코어가 body.fat과 BMI에 저장되어 있다. 두 변수의 관계를 나타내는 산포도를 그리고 상관계수를 구하시오. 3.2.4.4 Exercise batting(UsingR) 데이터는 2002년 메이저리그 통계자료이다. 스트라이크아웃 (SO)와 홈런 (HR)의 상관계수를 구하고 산점도를 그리시오. 3.2.5 Bivariate categorical data 두 종류의 짝데이터가 모두 범주형일 경우에 그 연관성을 정량화하는 방법에 대해서 알아보겠습니다. 3.2.5.1 Contingency tables 범주형 데이터에는 summarized 된 데이터와 unsummarized 된 데이터가 있을 수 있으며 두 경우에 분석하는 전략이 다를 수 있습니다. 일반적으로 범주형 데이터는 각 샘플의 그룹 정보를 표시하여 나타내며 분석을 위해서는 이러한 그룹 정보를 기준으로 각 그룹에 해당하는 샘플의 갯수를 카운팅하여 contingency table (분할표)로 변환하여 분석을 수행하게 됩니다. 두 범주형 변수의 경우는 two-way contingency table로 나타낼 수 있습니다. R에서는 다음과 같은 방법으로 테이블을 만듭니다. rbind(c(56,8), c(2,16)) cbind(c(56,2), c(8,16)) seatbelts &lt;- matrix(c(56, 2, 8, 16), nrow=2) rownames(seatbelts) &lt;- c(&quot;buckled&quot;,&quot;unbuckled&quot;) colnames(seatbelts) &lt;- c(&quot;buckled&quot;,&quot;unbuckled&quot;) seatbelts rownames(seatbelts) &lt;- c(&quot;pa_buckled&quot;,&quot;pa_unbuckled&quot;) colnames(seatbelts) &lt;- c(&quot;ch_buckled&quot;,&quot;ch_unbuckled&quot;) seatbelts Unsummarized 데이터의 경우는 다음과 같이 table함수를 사용하여 해당 범주에 속하는 데이터의 갯수를 카운팅하고 테이블을 만듭니다. head(grades) str(grades) mytbl &lt;- table(grades$prev, grades$grade) 3.2.5.2 Measures of association for categorical data The chi-squared statistics 는 가장 널리 쓰이는 범주형 자료의 연관성 척도로 다음과 같이 정의됩니다. 수식의 “o”와 “e”는 각각 관측값과 예측값을 나타냅니다. 이 값이 클 경우 연관이 크다는 것입니다. \\[ chi-squared ~ statistic = \\sum \\frac{(f_o - f_e)^2}{f_e} \\] f &lt;- Freq ~ Survived + Class tbl &lt;- xtabs(f, data=titanic, subset=c(Sex==&quot;Female&quot;)) summary(tbl) seatbelt 데이터 부모와 아이들의 안전벨트를 매는 두 사건 (변수)가 독립이라면 \\(p(C, P) == p(C)p(P)\\) 즉, 결합확률이 각 확률을 곱한 것과 같고 기대값은 확률 x 전체 사건의 수(\\(N\\)) 이므로 다시 적으면 \\(N p(C,P) == N p(C)p(P)\\) 입니다. 여기서 \\(N p(C,P)\\)는 우리가 관측한 값으로 볼 수 있고 \\(N p(C) p(P)\\)는 독립을 가정한 상태에서 기대값이라고 볼 수 있습니다. seatbelts &lt;- matrix(c(56, 2, 8, 16), nrow=2) rownames(seatbelts) &lt;- c(&quot;pa_buckled&quot;,&quot;pa_unbuckled&quot;) colnames(seatbelts) &lt;- c(&quot;ch_buckled&quot;,&quot;ch_unbuckled&quot;) seatbelts fo &lt;- seatbelts fo ## marginal probability margin_rows &lt;- rowSums(fo)/sum(fo) margin_cols &lt;- colSums(fo)/sum(fo) fe &lt;- matrix(0, 2, 2,) rownames(fe) &lt;- rownames(fo) colnames(fe) &lt;- rownames(fo) ## expected numbers fe[1,1] &lt;- sum(fo)*margin_rows[1]*margin_cols[1] fe[1,2] &lt;- sum(fo)*margin_rows[1]*margin_cols[2] fe[2,1] &lt;- sum(fo)*margin_rows[2]*margin_cols[1] fe[2,2] &lt;- sum(fo)*margin_rows[2]*margin_cols[2] sum((fo-fe)^2 / fe) ## use chisq.test function chisq.test(fo, correct=F) 3.2.5.3 Exercise UScereal 데이터셋은 미국 식료품점의 선반에 진열된 시리얼 제품의 정보에 대한 데이터임. 시리얼 생산 브랜드와 (UScereal$mfr) 디스플레이되는 floor 층 수 (UScereal$shelf) 관계를 나타내는 테이블을 구해서 tbl 변수에 저장하고 출력하시오 library(MASS) head(UScereal) str(UScereal) ?UScereal 브랜드와 진열 층 수와의 관계를 barplot으로 표현하시오 테이블의 각 cell 별 기대값을 구하고 chisqure 값을 구하시오 tbl &lt;- as.matrix(table(UScereal$mfr, UScereal$shelf)) 이 저작물은 크리에이티브 커먼즈 저작자표시-비영리-변경금지 4.0 국제 라이선스에 따라 이용할 수 있습니다. "],
["bioconductor.html", "Chapter 4 Bioconductor 4.1 Working with objects 4.2 Discovering, installing, and learning how to use Bioconductor packages 4.3 Data structure and management for genome-scale experiments 4.4 Biostrings package for sequence analysis 4.5 Download sequence information from NCBI", " Chapter 4 Bioconductor Bioconductor는 바이오인포메틱스를 위한 R기반의 데이터, 메소드, 그리고 패키지들의 모음입니다. 2002년 microarray 데이터 분석을 위한 플랫폼으로 시작되었으며 현재 1,300개 이상의 패키지로 구성되어 있습니다. R은 분산형 오픈소스이나 Bioconductor는 Full-time developer들에 의해서 유지되고 있습니다. CRAN에 배포되지 않고 CRAN에 비해 더 많은 필수 자료들 (vignettes 등)이 필요하며 높은 수준으로 quality control이 되고 있습니다. 현재 RNA-seq, ChIP seq, copy number analysis, microarray methylation, classic expression analysis, flow cytometry 등 다양한 분야의 데이터 분석에 사용되고 있습니다. 특징 Bioconductor 코어 개발 그룹은 사용자들이 지놈스케일 데이터를 더 편리하게 다루룰 수 있도록 데이터의 구조를 개발하는데 많은 시간을 들입니다. 지놈스케일의 서열이나 발현등 대용량 데이터 관리 통계적 분석을 용이하게 수행하기 위한 전처리 분자수준의 현상과 생장이나 질병 등 표현형수준의 관계를 규명하기 위한 정량 데이터 통합 재사용 가능한 데이터를 위한 관리 4.1 Working with objects 객체지향프로그래밍 (OOP)은 복잡한 문제를 프로그래밍할 때 발생되는 코드의 복잡성을 해결할 수 있는 하나의 방안으로 1990년대부터 많이 사용되었습니다. Genome 스케일의 experiment나 annotation은 대표적인 복잡한 데이터 중 하나 입니다. bioconcuctor는 OOP의 개념을 도입하여 이러한 생물학 데이터를 구조화하고 효율적으로 데이터를 관리하고 있습니다. Class와 Object, Instance 개념을 먼저 이해할 필요가 있습니다. 엄밀히 따지면 Object는 우리가 구현할 대상, Class는 설계도, Instance는 실제 구현한 대상 이라고 이해하시면 좋지만 가끔 Instance와 Object는 같은 의미로 사용되기도 합니다. 예를 들어 우리가 연구하는 사람, 원숭이, 제브라피쉬 라는 object들의 정보를 저장한다고 생각해 봅니다. 이 경우 각 객체들이 공통적으로 name, age, genome 등의 정보를 가지고 있고 그 기능적 특징 또한 유사하므로 이러한 정보가 저장되는 공간을 갖는 생명체라는 개념적 설계도를 (Class) 먼저 만듭니다. 그리고 해당 클래스의 H.sapiens, D. rerio, B. Ape, C. goeldii 를 만들면 각 객체의 구성 요소를 일일히 구현할 필요 없이 필요한 정보를 미리 정해진 구조에 맞게 저장 해주면 됩니다. Bioconductor에서 OOP 개념은 다음과 같습니다. class - 복잡한 데이터 구조의 틀 object - 특정 클래스가 특정 구현된 실례 (instance) method - 특정 클래스의 구현된 기능 (get/set) 그런데 이러한 class가 무수히 존재하며 각 name, age 등의 정보에 접근할 수 있는 method들을 제공하고 있습니다. class마다 사용 가능한 method가 어떠한 정보가 있는지 알기 위해서 methods()라는 함수를 사용합니다. 예를 들어 객체 Homo.sapience를 살펴보면 다음과 같습니다. library(Homo.sapiens) class(Homo.sapiens) ?OrganismDb The OrganismDb class is a container for storing knowledge about existing Annotation packages and the relationships between these resources. methods(class=class(Homo.sapiens)) genes(Homo.sapiens)[1:10] exons(Homo.sapiens)[1:10] homo_seq &lt;- seqinfo(Homo.sapiens) class(homo_seq) ?Seqinfo A Seqinfo object is a table-like object that contains basic information about a set of genomic sequences. … length(homo_seq) seqnames(homo_seq) bioconductor에는 대용량 정보가 object 형태로 구조화되어 저장되어 있으며 library()함수로 읽어올 수 있고 다양한 함수로 해당 object의 정보를 읽어올 수 있습니다. 4.2 Discovering, installing, and learning how to use Bioconductor packages https://www.bioconductor.org Discovery Use &gt;&gt; Software, Annotation, Experiment Software: 분석을 위한 툴 모음 Annotation: 유전자 symbol/ID mapping, gene ontology 기반 유전자 분류, 유전체상에서 exon, transcript, gene 등의 위치, 단백질 기능 등 Experiment data: 학습 가능할 정도의 Highly curated datasets (실험 데이터) Workflow: 특정 데이터 분석을 위한 프로세스 모음 Installation BiocManager를 먼저 설치하고 해당 패키지를 설치하시기 바랍니다. BiocManager에는 available()이라는 함수로 (특정 문자가 포함된) 사용 가능한 패키지를 검색할 수 도 있습니다. Use &gt;&gt; Software &gt;&gt; IRanges if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;IRanges&quot;) ## .libPaths() Learning and support Learn &gt;&gt; Support site library(IRanges) vignette(package=&quot;IRanges&quot;) browseVignettes(&quot;IRanges&quot;) vignette(&quot;IRangesOverview&quot;, package=&quot;IRanges&quot;) ir1 &lt;- IRanges(start=1:10, width=10:1) ir1 class(ir1) methods(class=&quot;IRanges&quot;) example(IRanges) ?IRanges ??IRanges 4.3 Data structure and management for genome-scale experiments 연구를 수행하면서 잘못된 데이터 관리로 인한 손실을 줄이기 위해서는 고도로 효율적이고 신뢰성 높은 툴이 필요합니다. 일반적으로 사용되는 엑셀 기반의 데이터 관리는 신뢰성과 파이프라인 측면에서 적합하지 않습니다. 즉, 특정 파이프라인을 만들어 놓고 이에 따라서 일관적으로 데이터를 관리할 때 높은 신뢰성의 데이터를 확보할 수 있고 과학적 추론의 바탕이 될 수 있습니다. 따라서 복잡한 데이터의 구조를 체계적으로 정의하고 정형화된 도구들로 분석 파이프라인을 개발할 필요가 있습니다. 4.3.1 ExpressionSet Class Biobase 패키지는 지놈 데이터를 관리하기 위한 표준화된 데이터 구조 class인 ExpressionSet를 제공합니다. library(Biobase) ?ExpressionSet data(sample.ExpressionSet) sample.ExpressionSet #browseVignettes(&quot;Biobase&quot;) #methods(class=&quot;ExpressionSet&quot;) featureNames(sample.ExpressionSet)[1:5] sampleNames(sample.ExpressionSet)[1:5] expression_data &lt;- exprs(sample.ExpressionSet) dim(expression_data) feature_data &lt;- fData(sample.ExpressionSet) dim(feature_data) pheno_data &lt;- pData(sample.ExpressionSet) dim(pheno_data) 급성 림프구성 백혈병 데이터 library(ALL) data(ALL) class(ALL) ALL browseVignettes(&quot;ALL&quot;) #methods(class=class(ALL)) pData(ALL) pData(ALL)$age fData(ALL) ## phenoData(ALL) varMetadata(phenoData(ALL)) featureData(ALL) 메타데이터는 데이터(data)에 대한 데이터로서 일반적으로는 어떤 목적을 가지고 만들어진 데이터로 정의됩니다. Gene expression omnibus (GEO) GEO는 microarray, next-generation sequencing 등의 high-throughput 유전체 데이터를 보유한 공공 저장소입니다. 대규모 기능유전체 데이터베이스 데이터 기탁 쉽게 만들고 고수준 QC 유지 사용하기 쉬운 인터페이스 유지 GEO library(GEOquery) browseVignettes(&quot;GEOquery&quot;) The GDS class gds &lt;- getGEO(filename=system.file(&quot;extdata/GDS507.soft.gz&quot;,package=&quot;GEOquery&quot;)) class(gds) methods(class=class(gds)) Table(gds) dataTable(gds) show(gds) Columns(gds) The GSM class gsm &lt;- getGEO(filename=system.file(&quot;extdata/GSM11805.txt.gz&quot;,package=&quot;GEOquery&quot;)) methods(class=class(gsm)) head(Meta(gsm)) Table(gsm)[1:5,] dim(Table(gsm)) Columns(gsm) The GSE class gse &lt;- getGEO(filename=system.file(&quot;extdata/GSE781_family.soft.gz&quot;,package=&quot;GEOquery&quot;)) methods(class=class(gse)) head(Meta(gse)) names(GSMList(gse)) class(GSMList(gse)[[1]]) ExpressionSet class의 GES 데이터 받기 GSE2553 gse2553 &lt;- getGEO(&#39;GSE2553&#39;,GSEMatrix=TRUE) gse2553 class(gse2553) class(gse2553[[1]]) mygse &lt;- gse2553[[1]] pData(mygse)[1:10,1:3] GDS 데이터를 ExpressionSet class로 변환하기 gds &lt;- getGEO(filename=system.file(&quot;extdata/GDS507.soft.gz&quot;,package=&quot;GEOquery&quot;)) class(gds) eset &lt;- GDS2eSet(gds, do.log2=TRUE) eset ## boxplot/vioplot for the 17 samples 급성 림프구성 백혈병 데이터 (Annotation) library(ALL) data(ALL) ALL featureData(ALL) ## if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;hgu95av2.db&quot;) library(hgu95av2.db) browseVignettes(&quot;hgu95av2.db&quot;) help(package=&quot;hgu95av2.db&quot;) featureNames(ALL)[1:10] ids &lt;- featureNames(ALL)[1:10] as.list(hgu95av2ENTREZID[ids]) 4.4 Biostrings package for sequence analysis 먼저 Biostrings는 아래와 같이 Bioconductor에서 제공하는 코드를 이용해서 설치할 수 있습니다. if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;Biostrings&quot;) library(Biostrings) Biostrings 패키지는 기본적으로 XString, XStringSet, XStringViews 3가지의 class를 정의하고 있습니다. XString은 DNA나 RNA, AA 등 생물학적 서열 한 가닥을 다루기위한 클래스이며 XStringSet은 여러 가닥을 다루기위한 클래스 입니다. 다음 내장변수 들은 Biostrings 패키지를 로드하면 자동으로 저장되는 변수들로 생물학적 서열을 미리 정의해 놓았습니다. DNA_BASES DNA_ALPHABET IUPAC_CODE_MAP 위 변수들을 이용하면 다음처럼 sample() 함수를 이용해서 랜덤하게 DNA 서열을 얻을 수 있습니다. DNA_BASES가 4개 길이를 갖는 벡터인데 이 중 10개를 뽑으려면 replace=T로 해야 합니다. x0 &lt;- sample(DNA_BASES, 10, replace = T) x0 x1 &lt;- paste(x0, collapse=&quot;&quot;) x1 XString 클래스 특히 DNAString 클래스의 사용법은 다음 코드를 통해 익힐 수 있습니다. length 함수는 핵산의 갯수를 (DNAStringSet 타입의 변수에서 length는 DNA 가닥의 갯수이며 핵산의 갯수는 nchar함수로 얻어낼 수 있습니다. toString은 DNAString 타입을 단순 문자열로 변환해주는 함수이며 상보서열, 역상보서열 등의 정보도 complement, reverseComplement 등을 사용하여 찾아낼 수 있습니다. x0 &lt;- paste(sample(DNA_BASES, 10, replace = T), collapse=&quot;&quot;) x1 = DNAString(x0) class(x0) class(x1) length(x1) toString(x1) complement(x1) Biostrings::complement(x1) reverseComplement(x1) DNAString의 인덱싱은 vector (string)과 같으며 DNAStringSet은 list의 인덱싱과 같습니다. ## indexing x1[1] x1[1:3] subseq(x1, start=3, end=5) subseq(x1, 3, 5) ## letter frequency alphabetFrequency(x1, baseOnly=TRUE, as.prob=TRUE) letterFrequency(x1, c(&quot;G&quot;, &quot;C&quot;), as.prob=TRUE) Exercise 시작코돈과 종결코돈이 있는 길이 36bp 짜리 DNA (랜덤) 서열을 만들고 GC 비율을 계산하시오 DNAStringSet class는 여러개의 DNAString 을 모아 놓은 집합이라고 보면 됩니다. length 함수는 DNA string의 갯수이며 width 또는 nchar 함수로 각 string의 길이를 구할 수 있으며 이 외 대부분의 DNAString 에서 사용되는 함수가 동일하게 사용될 수 있습니다. x0 &lt;- c(&quot;CTC-NACCAGTAT&quot;, &quot;TTGA&quot;, &quot;TACCTAGAG&quot;) x1 &lt;- DNAStringSet(x0) class(x0) class(x1) names(x1) names(x1) &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;) length(x1) width(x1) subseq(x1, 2, 4) x1[[1]] x1[1] x3 &lt;- DNAString(&quot;ATGAGTAGTTAG&quot;) x4 &lt;- c(x1, DNAStringSet(x3)) x4[-1] x4 alphabetFrequency(x1, baseOnly=TRUE, as.prob=TRUE) letterFrequency(x1, c(&quot;G&quot;, &quot;C&quot;), as.prob=TRUE) rowSums(letterFrequency(x1, c(&quot;G&quot;, &quot;C&quot;), as.prob=TRUE)) subseq(x4, 2, 4) 아래는 가장 직관적으로 생각할 수 있는 for를 이용한 방법입니다. 즉, 10개 저장소를 갖는 x0 변수를 미리 생성해 두고 for 문을 돌면서 서열을 하나씩 만들어 저장하는 방법입니다. x0 &lt;- rep(&quot;&quot;, 10) for(i in 1:length(x0)){ tmp &lt;- paste(sample(DNA_BASES, 30, replace = T), collapse=&quot;&quot;) x0[i] &lt;- paste(&quot;ATG&quot;, tmp, &quot;TAG&quot;, sep=&quot;&quot;) } x0 위 코드를 함수로 만들어 보겠습니다. random dna를 만들 때 길이만 다를뿐 같은 코드를 반복해서 사용하고 있습니다. 이럴 경우 DNA 길이를 사용자가 정해주도록 input parameter로 하고 해당 파라메터를 받아 DNA를 만들어 주는 함수를 만들어 사용하면 편리합니다. random_dna &lt;- function(len){ tmp &lt;- paste(sample(DNA_BASES, len, replace = T), collapse=&quot;&quot;) x0 &lt;- paste(&quot;ATG&quot;, tmp, &quot;TAG&quot;, sep=&quot;&quot;) return(x0) } random_dna(len=30) random_dna(len=40) 파라메터로 넘겨진 len 값이 sample 함수의 len에 사용된 것을 참고하세요. 이제 길이 30bp짜리 10개의 서열을 반복해서 만들 때 위 함수를 앞서와 같이 for문을 이용하여 10번 반복해서 실행해 주면 같은 결과를 얻습니다. 위와 같이 함수를 만들어 두면 언제든 DNA 서열을 만들 때 재사용 할 수 있습니다. x0 &lt;- rep(&quot;&quot;, 10) for(i in 1:length(x0)){ x0[i] &lt;- random_dna(30) } x0 그런데 R에는 apply 와 같은 행렬연산 함수가 있어서 for문을 사용하지 않고 편리하게 반복문을 실행할 수 있습니다. replicate 함수는 apply와 같은 기능으로 list나 vector 변수에 대해서 사용할 수 있습니다. 즉, 다음과 같이 사용자가 원하는 함수를 반복해서 실행하고 반복 수 만큼의 길이를 갖는 결과를 반환합니다. x0 &lt;- replicate(10, random_dna(30)) x0 x1 &lt;- DNAStringSet(x0) x1 위 x0 스트링들을 XStringSet으로 바꾸고 GC 비율을 구한 후 bargraph를 그리겠습니다. gc_ratio가 G와 C의 비율값을 저장한 10x2 테이블이므로 x축에 10개의 서열과 각 서열의 GC비율을 나타내고 y축에 비율 값을 그리는 것으로 생각한 후 ggplot의 aes와 파라메터를 적절히 지정해 줍니다. x1 &lt;- DNAStringSet(x0) gc_ratio1 &lt;- letterFrequency(x1, c(&quot;G&quot;, &quot;C&quot;), as.prob=TRUE) gc_ratio2 &lt;- rowSums(gc_ratio1) barplot(gc_ratio2, beside=T) Biostrings의 또 다른 class인 XStringView는 XString class의 DNA서열을 사용자가 원하는대로 볼 수 있는 인터페이스를 제공합니다. 사용법은 다음과 같습니다. x2 &lt;- x1[[1]] Views(x2, start=1, width=20) Views(x2, start=1, end=4) Views(x2, start=c(1,3), end=4) Views(x2, start=c(1,3,4), width=20) Views(x2, start=c(1,3,4), width=20) i &lt;- Views(x2, start=c(1,3,4), width=20) 다음과 같이 한 서열에 대한 여러 부분의 서열 조각도 볼 수 있으며 gaps 함수는 매개변수로 주어진 서열 view의 구간을 제외한 나머지 구간의 서열을 보여주는 함수입니다. successiveviews 함수는 처음 서열부터 매개변수 width에 주어진 갯수 만큼의 서열을 보여주며 rep() 함수를 이용해서 서열의 처음부터 끝까지 보여주는 기능을 합니다. v &lt;- Views(x2, start=c(1,10), end=c(3,15)) gaps(v) successiveViews(x2, width=20) successiveViews(x2, width=rep(20, 2)) successiveViews(x2, width=rep(20, 3)) 서열 읽고 쓰기 writeXStringSet(DNAStringSet(x0), &quot;myfastaseq.fasta&quot;, format=&quot;fasta&quot;) myseq &lt;- readDNAStringSet(&quot;myfastaseq.fasta&quot;, format=&quot;fasta&quot;) myseq Exercise 1000bp 길이의 랜덤 DNA 서열을 만들고 40bp 단위의 길이로 보는 코드를 만들어 보겠습니다. 앞서 만들어둔 random_dna() 함수를 사용하면 되며 successiveview 함수를 사용해야 하므로 DNAString으로 변환이 필요하며 서열의 길이에 따라서 rep() 를 이용하여 반복 횟수를 자동 계산합니다. 4.5 Download sequence information from NCBI 전세계 연구자들이 서열 데이터를 분석하는데 가장 많이 이용하는 사이트 중 하나가 NCBI 이며 따라서 NCBI에서는 연구자들이 데이터베이스에 접근하기위한 편리한 방법을 제공하고 있고 그 중 하나가 Entrez 입니다. R에서도 Entrez 기능을 도입한 package들이 제공되고 있으며 그 중 하나가 rentrez 입니다. https://www.ncbi.nlm.nih.gov/books/NBK25500/ 이 곳의 Downloading Full Records 를 참고하시면 좋습니다. Entrez는 대략적으로 다음 9개의 유틸리티를 제공합니다. EInfo (database statistics) ESearch (text searches) EPost (UID uploads) ESummary (document summary downloads) EFetch (data record downloads) ELink (Entrez links) EGQuery (global query) ESpell (spelling suggestions) ECitMatch (batch citation searching in PubMed) 이 중 ESerach, EPost, ESummary, EFetch 등이 많이 사용하는 유틸이며 정보를 다운로드 받을 경우는 EFetch 를 주로 사용하게 됩니다. 예제로 뎅기바이러스 서열 4종을 다운로드 하겠습니다. NCBI의 accession 번호를 알 경우이며 각각에 대한 accession no.는 NC_001477, NC_001474, NC_001475 and NC_002640 입니다. library(rentrez) entrez_dbs() entrez_db_summary(&quot;nuccore&quot;) ## acc &lt;- c(&quot;NC_001477&quot;, &quot;NC_001474&quot;, &quot;NC_001475&quot;, &quot;NC_002640&quot;) all_recs &lt;- entrez_fetch(db=&quot;nuccore&quot;, id=acc[1], rettype=&quot;fasta&quot;) cat(strwrap(substr(all_recs, 1, 500)), sep=&quot;\\n&quot;) write(all_recs, file=&quot;myseq.fasta&quot;) dang &lt;- readDNAStringSet(&quot;myseq.fasta&quot;, format=&quot;fasta&quot;) ## r_search &lt;- entrez_search(db=&quot;pubmed&quot;, term=&quot;R Language&quot;) all_recs &lt;- entrez_fetch(db=&quot;pubmed&quot;, id=r_search$ids, rettype=&quot;fasta&quot;) write(all_recs, file=&quot;mypub.txt&quot;) 이 저작물은 크리에이티브 커먼즈 저작자표시-비영리-변경금지 4.0 국제 라이선스에 따라 이용할 수 있습니다. "],
["data-science-and-tidyverse.html", "Chapter 5 Data science and tidyverse 5.1 Tidy data structure 5.2 Analysis Goal (ALL dataset) 5.3 Apply functions 5.4 Data manipulation with dplyr", " Chapter 5 Data science and tidyverse tidyverse (https://www.tidyverse.org/)는 데이터 사이언스를 위한 R 기반의 독창적인 패키지들의 모음입니다. Rstudio의 핵심 전문가인 해들리위컴이 (Hadley Wickham) 중심이 되어 만들어 졌으며 기존의 툴보다 쉽고 효율적으로 데이터 분석을 수행할 수 있습니다. 5.1 Tidy data structure 데이터의 변수와 값을 구분하는 일은 적절한 데이터 분석을 위해 필수적인 과정입니다. 특히 복잡하고 사이즈가 큰 데이터일 경우는 더욱 중요할 수 있으나 경험에 의존해서 구분을 하는 것이 대부분 입니다. Tidy data는 이러한 변수와 값의 명확한 구분과 활용을 위한 데이터 구조중 하나 입니다 (Hadley Wickham. Tidy data. The Journal of Statistical Software, vol. 59, 2014). Long형 데이터로 알려져 있기도 합니다. 참고로 Wide형 데이터의 경우 샘플 데이터가 늘어날수록 row에 쌓이고 새로운 변수는 column에 쌓이는 방식으로 데이터가 확장되는 형태 입니다. 엑셀에서 볼 수 있는 일반적인 형식으로 다음 그림과 같습니다. Long형 데이터의 경우 ID, variable, value 세가지 변수만 기억하면 되겠습니다. 위 wide형 데이터 경우를 보면 ID, variable, 그리고 value 이 세가지 요인이 주요 구성 요소임을 알 수 있습니다. Long형으로 변환할 경우 샘플을 참조할 수 있는 어떤 변수 (variable)도 ID가 될 수 있으며 2개 이상의 변수가 ID로 지정될 수 있습니다. 참고로 ID를 지정할 경우 해당 ID는 가능하면 중복되지 않는 값들을 갖는 변수를 사용해야 식별자로서 기능을 적절히 수행할 수 있습니다. Long형을 사용할 경우 데이터의 변수가 늘어나도 행의 수만 늘어나므로 코딩의 일관성과 변수들의 그룹을 만들어서 분석하는 등의 장점이 있습니다. 아래는 새로운 변수 F가 추가될 때 long 형 데이터에 데이터가 추가되는 경우를 나타낸 그림 입니다. 일반적으로 얻어지는 데이터의 형태는 wide형이며 이를 Long형으로 변환하기 위해서는 tidyverse 패키지에 속한 tidyr 패키지의 pivot_longer와 pivot_wider를 사용합니다. 또한 reshape2 패키지의 melt함수와 그 반대의 경우 dcast 함수를 사용할 수도 있습니다. 본 강의에서는 tidyr 패키지를 사용합니다. wide형 데이터를 long형으로 변환하는 작업을 melting 이라고 합니다. airquality 데이터는 전형적인 wide형 데이터로 특정 날짜에 네 개의 변수에 해당하는 값들을 측정했습니다. 이 데이터를 long형으로 바꿀 경우 ID를 날짜로 하면 데이터들을 식별 할 수 있습니다. 그런데 날짜는 변수가 Month와 Day두 개로 나누어져 있으므로 다음과 같이 두 변수를 식별 변수로 (ID로) 사용 합니다. 확인을 위해 상위 5개의 데이터만 가지고 형 변환을 진행해 보겠습니다. library(tidyr) myair &lt;- airquality[1:5,] myair_mlt &lt;- pivot_longer(myair, c(&quot;Ozone&quot;, &quot;Solar.R&quot;, &quot;Wind&quot;, &quot;Temp&quot;)) myair_mlt myair_mlt2 &lt;- pivot_longer(myair, c(Ozone, Solar.R, Wind, Temp)) myair_mlt2 myair_mlt3 &lt;- pivot_longer(myair, !c(Month, Day)) myair_mlt3 ggplot을 이용한 그래프 작성에는 위와 같은 long형 데이터가 주로 사용됩니다. R을 이용한 데이터 가시화는 dplyr 패키지로 wide형 데이터를 편집하고 pivot_longer 함수로 long형 데이터로 변환 후 ggplot을 이용하는 방식으로 수행합니다. 두 데이터 포멧에 대한 좀 더 구체적인 내용은 다음 링크를 참고하시기 바랍니다. https://www.theanalysisfactor.com/wide-and-long-data/ 5.2 Analysis Goal (ALL dataset) 성별별로 각 유전자들의 평균 발현양 구하기 성별별로 각 유전자들의 최고 발현값 구하기 성별별로 각 유전자들의 발현값 차이 검정 하기 library(ALL) library(hgu95av2.db) data(ALL) ## data ex_data &lt;- exprs(ALL)[1:100,] ph_data &lt;- pData(ALL)[,c(&quot;cod&quot;, &quot;sex&quot;, &quot;BT&quot;)] ## remove missing | duplicated genes ph_data &lt;- ph_data[complete.cases(ph_data),] feature_names &lt;- featureNames(ALL)[1:100] gene_names &lt;- unlist(as.list(hgu95av2SYMBOL[feature_names])) idx &lt;- which(is.na(gene_names) | duplicated(gene_names)) ex_data &lt;- ex_data[-idx,] rownames(ex_data) &lt;- gene_names[-idx] ex_data[1:3,1:3] 성별별로 각 유전자들의 평균 발현양 구하기 ## tip x &lt;- 1:10 sprintf(&quot;%05d&quot;, x) ## male selnames &lt;- ph_data$cod[ph_data$sex==&quot;M&quot;] selnames &lt;- sprintf(&quot;%05d&quot;, as.numeric(selnames)) selnames2 &lt;- selnames[!is.na(selnames)] ex_data_male &lt;- ex_data[,selnames2] colidx &lt;- complete.cases(t(ex_data_male)) ex_data_male2 &lt;- ex_data_male[,colidx] ## female selnames &lt;- ph_data$cod[ph_data$sex==&quot;F&quot;] selnames &lt;- sprintf(&quot;%05d&quot;, as.numeric(selnames)) selnames2 &lt;- selnames[!is.na(selnames)] ex_data_female &lt;- ex_data[,selnames2] colidx &lt;- complete.cases(t(ex_data_female)) ex_data_female2 &lt;- ex_data_female[,colidx] ## average male_mean &lt;- rowMeans(ex_data_male2) female_mean &lt;- rowMeans(ex_data_female2) exp_mean &lt;- data.frame(male_mean, female_mean) head(exp_mean) ## visualization barplot(t(exp_mean), beside=T) ## diff &lt;- male_mean-female_mean plot(diff) plot(male_mean, female_mean) abline(a=0, b=1) 성별별로 각 유전자들의 최고 발현값 구하기 male_val &lt;- rep(0, nrow(ex_data_male2)) for(i in 1:nrow(ex_data_male2)){ male_val[i] &lt;- max(ex_data_male2[i,]) } names(male_val) &lt;- rownames(ex_data_male2) female_val &lt;- rep(0, nrow(ex_data_female)) for(i in 1:nrow(ex_data_female)){ female_val[i] &lt;- max(ex_data_female[i,]) } names(female_val) &lt;- rownames(ex_data_female) exp_val &lt;- data.frame(male_val, female_val) rownames(exp_val) &lt;- rownames(ex_data) barplot(t(exp_mean), beside=T) 성별별로 각 유전자들의 발현값 차이 검정 하기 5.3 Apply functions apply는 데이터를 변형하기 위한 함수라기 보다는 데이터를 다룰 때 각 원소별, 그룹별, row, 또는 column 별로 반복적으로 수행되는 작업을 효율적으로 수행할 수 있도록 해주는 함수입니다. apply 계열의 함수를 적절히 사용하면 효율성이나 편리성 뿐만 아니라 코드의 간결성 등 많은 장점이 있습니다. apply의 두 번째 인자인 margin의 값으로 (?apply참고) 여기서는 2가 사용되었으며 margin 값이 1인지 2인지에 따라서 다음과 같이 작동을 합니다. mean외에도 다양한 함수들이 사용될 수 있으며 아래와 같이 임의의 함수를 만들어서 사용할 수 도 있습니다. 아래 코드에서는 function(x)...로 바로 함수의 정의를 넣어서 사용했으나 그 아래 mysd 함수와 같이 미리 함수 하나를 만들고 난 후 함수 이름을 이용해서 apply를 적용할 수 있습니다. nums &lt;- sample(1:100, 100, replace = T) df &lt;- matrix(nums, nrow=20, ncol=5) apply(df, 2, sd) apply(df, 2, mean) apply(df, 1, sd) sd(df[1,]) apply(df, 2, sd, na.rm=T) apply(df, 2, function(x){ xmean &lt;- mean(x, na.rm=T) return(xmean) }) apply 함수 외에도 sapply, lapply, mapply 등의 다양한 apply계열 함수가 쓰일 수 있습니다. 먼저 lapply는 matrix 형태 데이터가 아닌 list 데이터에 사용되어 각 list 원소별로 주어진 기능을 반복해서 수행하며 sapply는 lapply와 유사하나 벡터, 리스트, 데이터프레임 등에 함수를 적용할 수 있고 그 결과를 벡터 또는 행렬로 반환합니다. l &lt;- list() l[[1]] &lt;- sample(1:100, 100, replace = T) l[[2]] &lt;- sample(1:100, 100, replace = T) l[[3]] &lt;- sample(1:100, 100, replace = T) l[[4]] &lt;- sample(1:100, 100, replace = T) lapply(l, sd) sapply(1:4, function(x){ sample(1:100, 100, replace = T) }) 성별별로 각 유전자들의 최고 발현값 구하기 ## male_val &lt;- apply(ex_data_male2, 1, max) female_val &lt;- apply(ex_data_female2, 1, max) exp_val &lt;- data.frame(male_val, female_val) rownames(exp_val) &lt;- rownames(ex_data) barplot(t(exp_mean), beside=T) 성별별로 각 유전자들의 발현값 차이 검정 하기 ## x &lt;- ex_data_male2[1,] y &lt;- ex_data_female2[1,] fit &lt;- t.test(x, y) ## mytest &lt;- function(x){ fit &lt;- t.test(x[1:86], x[87:128]) ## no good z &lt;- c(tstat=fit$statistic, pval=fit$p.value) return(z) } a &lt;- c(x, y) mytest(a) new_data &lt;- cbind(ex_data_male, ex_data_female) test_results &lt;- apply(new_data, 1, mytest) test_results &lt;- t(test_results) test_results &lt;- data.frame(test_results) barplot(test_results$tstat.t, col=&quot;green&quot;) mycol &lt;- rep(&quot;green&quot;, length(test_results$pval)) barplot(test_results$tstat.t, col=mycol) mycol[test_results$pval&lt;0.1] &lt;- &quot;red&quot; barplot(test_results$tstat.t, col=mycol) ph_data$BT 5.4 Data manipulation with dplyr dplyr (https://dplyr.tidyverse.org/) 은 ggplot2을 개발한 해들리위컴이 (Hadley Wickham) 중심이 되어 만들어 졌으며 ggplot2와 함께 tidyverse의 (https://www.tidyverse.org/) 핵심 패키지 입니다. dplyr은 데이터를 다루는 크기나 분석의 속도, 편의성을 향상시켜 새롭게 만들어놓은 패키지 입니다. 기존 apply와 같은 행렬 연산 기능과 subset, split, group 와 같은 행렬 편집 기능을 더하여 만들어진 도구라고 할 수 있습니다. dplyr의 전신이라 할 수 있는 plyr 패키지는 다음과 같이 설명이 되어 있습니다. A set of tools for a common set of problems: you need to split up a big data structure into homogeneous pieces, apply a function to each piece and then combine all the results back together. 즉 split-apply-combine 세 가지 동작을 쉽게 할 수 있도록 만들어 놓은 툴 입니다. R이 다른 언어에 비해 데이터 분석에서 주목을 받는 이유로 split, apply 등의 행렬 연산 함수가 발달한 것을 내세우는데 dplyr은 이들을 보다 더 편리하게 사용할 수 있도록 만들어 놓은 것 입니다. 5.4.1 dplyr - pipe operator dplyr의 사용을 위해서는 여러 명령을 연속적으로 수행하도록 해주는 %&gt;% 파이프 오퍼레이터의 이해가 필요합니다. 파이프 오퍼레이터의 작동법은 간단히 %&gt;%의 왼쪽 코드의 결과를 출력으로 받아 오른쪽 코드의 입력 (첫번째 파라미터의 값)으로 받아들이는 작동을 합니다 (단축키: Shift+Ctrl+m). 다음 예에서 보면 sin(pi) 와 같은 함수의 일반적인 사용법 대신 pi %&gt;% sin 처럼 사용해도 똑같은 결과를 보여줍니다. cos(sin(pi))와 같이 여러 합수를 중첩하여 사용할 경우와 비교해서 코드의 가독성이나 효율 측면에서 크게 향상된 방법을 제공해 줍니다. library(dplyr) pi %&gt;% sin sin(pi) pi %&gt;% sin %&gt;% cos cos(sin(pi)) 특히 %&gt;%는 이후 설명할 dplyr의 group_by, split, filter, summary 등의 행렬 편집/연산 함수를 빈번히 다양한 조합으로 쓰게되는 상황에서 더 큰 효과를 발휘할 수 있습니다. pipe operator의 왼쪽 구문의 결과가 오른쪽 구문의 첫 번째 파라미터의 입력 값으로 처리된다고 말씀 드렸습니다. 즉, 함수에서 사용되는 파라미터가 여러개일 경우가 있으므로 기본적으로 %&gt;% 의 왼쪽 구문의 출력 값은 오른쪽 구문 (함수)의 첫 번째 인자의 입력값으로 들어가는 것 입니다. 이는 다음 예들을 통해서 명확히 알 수 있습니다. 먼저 paste함수는 그 파라미터로 ,로 구분되는 여러개의 입력 값을 가질 수 있습니다. 따라서 다음 코드는 x가 paste의 첫 번째 파라미터로 들어가게 되어 \"1a\", \"2a\", \"3a\", \"4a\", \"5a\"로 a 앞에 x 값들이 붙어서 출력된 것을 알 수 있습니다. x &lt;- 1:5 x %&gt;% paste(&quot;a&quot;, sep=&quot;&quot;) 특정 데이터셋의 컬럼별 평균을 구하고 각 평균의 합을 구할 경우를 생각해 봅시다. R에서는 colMeans라는 특별한 함수를 제공하여 컬럼별로 평균을 계산해 줍니다. 그 후 sum 함수를 사용하여 최종 원하는 값을 얻을 수 있습니다. 이러한 코드를 %&gt;% 오퍼레이터를 사용한 경우의 코드와 비교해 볼 수 있습니다. x &lt;- data.frame(x=c(1:100), y=c(201:300)) sum(colMeans(x)) x &lt;- data.frame(x=c(1:100), y=c(201:300)) x %&gt;% colMeans %&gt;% sum 그럼 만약 두 번째 파라미터에 입력으로 왼쪽 구문의 출력을 받아들이고 싶을 경우는 place holer . 을 사용하면 되겠습니다. round 함수는 두 개의 파라미터를 설정할 있 이으며 digits 라는 두 번째 파라미터에 값을 pipe operator로 넘겨주고 싶을 경우 아래와 같이 표현할 수 있습니다. 6 %&gt;% round(pi, digits=.) round(pi, digits=6) 5.4.2 dplyr - Important functions 이제 본격적으로 dplyr 함수를 사용해 보겠습니다. dplyr을 구성하는 중요한 함수는 다음 6가지가 있습니다. select() - select columns filter() - filter rows arrange() - re-order or arrange rows mutate() - create new columns summarise() - summarise values group_by() - allows for group operations in the “split-apply-combine” concept join() - Merge two data.frames (left_join(), ’right_join(), 'inner_join(), ’full_join()`) 이 함수들은 %&gt;%와 함께 쓰이면서 강력한 성능을 발휘합니다. summarise 함수는 특정 값들의 통계 값을 계산해 주는 함수이며 그 외 5개 함수들은 행렬 편집을 위한 함수들로 보시면 되겠습니다. 간단한 예제를 수행하면서 각각의 기능을 살펴보고 왜 dplyr이 널리 사용되고 그 장점이 무엇인지 파악해 보도록 하겠습니다. iris 데이터는 세 종류의 iris 품종에 대한 꽃잎과 꽃받침의 length와 with를 측정해 놓은 데이터 입니다. head와 str 명령어를 %&gt;%를 이용해서 데이터를 살펴 봅니다. iris %&gt;% head(10) iris %&gt;% str 5.4.2.1 filter 먼저 아래와 같이 filter 함수를 사용해서 원하는 조건의 데이터 (샘플)을 골라낼 수 있습니다. library(dplyr) head(iris) iris %&gt;% filter(Species==&quot;setosa&quot;) iris %&gt;% filter(Species==&quot;setosa&quot; | Species==&quot;versicolor&quot;) iris %&gt;% filter(Species==&quot;setosa&quot; &amp; Species==&quot;versicolor&quot;) iris %&gt;% filter(Species==&quot;setosa&quot; | Species==&quot;versicolor&quot;) %&gt;% dim filter의 ,로 구분되는 매개변수는 and 로직으로 묶인 조건입니다. 지난 강좌에서 보셨듯 R에서 and는 &amp;, or는 |, 그리고 not은 ! 으로 사용하면 되며 filter에서 ,로 구분된 조건은 and와 같다고 보시면 되겠습니다. Image from (https://r4ds.had.co.nz/) 5.4.2.2 arrange arrange()는 지정된 변수를 기준으로 값의 크기순서로 샘플들의 배열 순서 즉, row의 순서를 바꾸는 기능을 수행합니다. 기본으로 크기가 커지는 순서로 정렬이 진행되며 작아지는 순서를 원할 경우 desc 함수를 사용할 수 있습니다. iris %&gt;% arrange(Sepal.Length) iris %&gt;% arrange(desc(Sepal.Length)) iris %&gt;% arrange(Sepal.Length, Sepal.Width) 5.4.2.3 select select() 는 주어진 데이터셋으로부터 관심있는 변수를 (column) 선택하여 보여줍니다. 다음 helper 함수들은 select 함수와 같이 유용하게 쓰일 수 있습니다. starts_with(“abc”) - “abc” 로 시작하는 문자열을 갖는 변수 이름 ends_with(“xyz”) - “xyz”으로 끝나는 문자열을 갖는 변수 이름 contains(“ijk”) - “ijk” 문자열을 포함하는 변수 이름 matches(“(.)\\1”) - 정규식, 반복되는 문자 head(iris) iris %&gt;% dplyr::select(Species, everything()) %&gt;% head(5) iris %&gt;% dplyr::select(Species, everything()) iris %&gt;% dplyr::select(-Species) iris %&gt;% dplyr::select(starts_with(&#39;S&#39;)) iris %&gt;% dplyr::select(obs = starts_with(&#39;S&#39;)) 아래는 matches 함수를 사용한 방법 입니다. 좀 더 복잡한 패턴을 적용하여 변수들을 선택할 수 있으며 grep 함수를 사용할 경우도 정규식 패턴을 적용할 수 있습니다. 아래 (.)\\\\1은 하나의 문자 .가 (어떤 문자든) 한 번 더 \\\\1 사용된 변수 이름을 말하며 이는 aavar 의 aa밖에 없으므로 aavar가 선택됩니다. grep에서 ^ 표시는 맨 처음을 나타내므로 ^S는 S로 시작하는 문자가 되겠습니다. 따라서 grep(\"^S\", colnames(iris))의 경우 컬럼 이름 중 S로 시작하는 이름은 True로 그렇지 않으면 False 값을 리턴합니다. iris2 &lt;- rename(iris, aavar = Petal.Length) select(iris2, matches(&quot;(.)\\\\1&quot;)) tmp &lt;-iris[,3:5] colnames(iris)[grep(&quot;^S&quot;, colnames(iris))] iris[,grep(&quot;^S&quot;, colnames(iris))] tmp 5.4.2.4 mutate mutate() 함수는 새로운 변수를 추가할 수 있는 기능을 제공하며 앞에서 배웠던 within()과 비슷하다고 볼 수 있습니다. 아래와 같이 mutate함수는 sepal_ratio라는 변수를 새로 만들어서 기존 iris 데이터들과 함께 반환해 줍니다. iris2 &lt;- iris %&gt;% mutate(sepal_ratio = Sepal.Length/Sepal.Width) head(iris2) 5.4.2.5 summarise summarise()는 data.frame내 특정 변수의 값들로 하나의 요약값/대푯값을 만들어 줍니다. summarise 함수는 단독으로 쓰이기 보다는 group_by() 기능과 병행해서 쓰이는 경우에 유용하게 쓰입니다. summarise_all() 함수를 사용하면 모든 변수에 대해서 지정된 함수를 실행합니다. iris %&gt;% summarise(mean(Sepal.Length), m=mean(Sepal.Width)) iris %&gt;% group_by(Species) %&gt;% summarise(mean(Sepal.Width)) iris %&gt;% group_by(Species) %&gt;% summarise_all(mean) iris %&gt;% group_by(Species) %&gt;% summarise_all(sd) 5.4.2.6 join join 함수는 데이터를 합해주는 기능을 수행하는 dplyr 패키지에 속한 함수 입니다. 네 가지 종류의 함수가 있으며 (left_join(), ’right_join(), 'inner_join(), ’full_join()) 기본적으로 공통되는 이름의 변수를 (key) 이용해서 공통되는 샘플끼리 자동으로 병합해 주는 기능을 수행합니다.by`에서 지정해준 파라메터의 값을 기준으로 기능이 수행 됩니다. df1 &lt;- data.frame(id=c(1,2,3,4,5,6), age=c(30, 41, 33, 56, 20, 17)) df2 &lt;- data.frame(id=c(4,5,6,7,8,9), gender=c(&quot;f&quot;, &quot;f&quot;, &quot;m&quot;, &quot;m&quot;, &quot;f&quot;, &quot;m&quot;)) inner_join(df1, df2, by=&quot;id&quot;) left_join(df1, df2, &quot;id&quot;) right_join(df1, df2, &quot;id&quot;) full_join(df1, df2, &quot;id&quot;) 5.4.3 code comparison 이제 split, apply, combine을 활용하여 평균을 구하는 코드와 dplyr 패키지를 사용하여 만든 코드를 비교해 보도록 하겠습니다. split은 factor형 변수인 Species를 기준으로 iris 데이터를 나누어 주는 역할을 하며 lapply는 list 형 데이터인 iris_split을 각 리스트의 각각의 원소들에 대해서 임의의 함수 function(x)... 를 수행하는 역할을 합니다. 마지막 data.frame으로 최종 경로를 combine 합니다. iris_split &lt;- split(iris, iris$Species) iris_means &lt;- lapply(iris_split, function(x){colMeans(x[,1:4])}) iris_means_df &lt;- data.frame(iris_means) iris_means_df 위 코드를 한 줄로 사용하여 최종 iris_means_df 데이터를 를 구한다면 다음과 같이 됩니다. 한눈에 코드가 들어오지 않고 이렇게 중첩해서 함수를 사용하는 습관은 어떤 프로그래밍 언어에서도 권장하지 않습니다. iris_means_df &lt;- data.frame(lapply(split(iris, iris$Species), function(x){colMeans(x[,1:4])})) 아래는 dplyr 패키지를 사용한 코드 입니다. iris_means_df2 &lt;- iris %&gt;% group_by(Species) %&gt;% summarise_all(mean) 위에서 보듯 dplyr 패키지를 사용할 경우 그 결과는 같으나 코드의 가독성과 효율성면에서 장점을 보여줍니다. iris 데이터를 받아서 Species에 명시된 그룹으로 나누고 mean 함수를 모든 컬럼에 대해서 사용하라는 의미 입니다. ggplot을 이용하여 각 평균에 대한 barplot을 그려보도록 하겠습니다. ggplot에서는 data만 명시해 주고 geom_bar에 aes와 stat을 모두 사용한 것이 다릅니다. ggplot 구문에서 지정해주는 aes 등의 옵션은 하위 geom_xxx 레이어들에 모두 적용이 되고 각 geom_xxx 레이어에서 지정해주는 aes는 해당 레이어에서만 효과를 나타냅니다. library(ggplot2) ggplot(iris_means_df) + geom_bar(aes(x=Species, y=Sepal.Length), stat=&quot;identity&quot;) 5.4.4 dplyr example iris dplyr패키지를 이용해서 iris 품종별로 꽃과 꽃받침의 넓이와 길이의 평균을 비교하는 bar그래프를 (error bar 포함) 그려보겠습니다. iris_mean &lt;- iris %&gt;% group_by(Species) %&gt;% summarise_all(mean) 이제 이 값들을 이용해서 barplot으로 그려봅니다. 그래프의 x축은 species별 Length나 Width mean 값으로 하고 y축은 각 해당하는 값들로 `stat=“identity”’로 넣어주면 될 듯 합니다. ggplot을 이용해서 그래프를 그리기 위한 long형 데이터로 전환해보면 다음과 같습니다. iris_mean_mlt &lt;- iris_mean %&gt;% pivot_longer(cols = -Species) ggplot(iris_mean_mlt, aes(x=name, y=value, fill=Species)) + geom_bar(stat = &quot;identity&quot;, position = &quot;dodge&quot;) error bar 구현을 위해서는 각 그룹별 표준편차 sd 값이 필요합니다. 동일한 방법으로 sd 데이터를 구합니다. iris_sd_mlt &lt;- iris %&gt;% group_by(Species) %&gt;% summarise_all(sd) %&gt;% pivot_longer(-Species) 이제 두 데이터를 병합 하겠습니다. 두 데이터를 병합할 때 key가 되는 변수가 필요하며 기본으로 동일한 이름을 가진 변수를 사용하지만 이 예제에서는 모든 변수가 동일한 이름을 가지고 있습니다. 따라서 by라는 옵션으로 key 변수를 지정해줄 수 있으며 다음과 같이 두 개 이상의 변수도 지정할 수 있습니다. iris_new &lt;- left_join(iris_mean_mlt, iris_sd_mlt, by=c(&quot;Species&quot;, &quot;name&quot;)) head(iris_new) 위와 같이 각 해당하는 샘플의 mean과 sd 값을 직접 비교해 보면 적절한 value 값들이 병합된 것을 알 수 있습니다. 단, value라는 변수 이름이 두 테이블에서 동일하게 사용되어 병합될 경우 value.x, value.y와 같이 자동으로 변수 이름이 다르게 할당 됩니다. 이제 위 데이터를 이용해서 barplot을 그려 보겠습니다. ggplot(iris_new, aes(x=name, y=value.x, fill=Species)) + geom_bar(stat=&quot;identity&quot;, position=&quot;dodge&quot;) 여기에 error bar를 추가하기 위해서는 다음과 같이 geom_errorbar라는 함수를 사용할 수 있습니다. 아래에서 position_dodge(0.9)는 error bar의 위치를 맞추기 위한 옵션으로 width를 사용할 경우는 일반적으로 position_dodge(0.9)를 사용한다고 외우는 것도 괜찮습니다. ggplot(iris_new, aes(x=name, y=value.x, fill=Species)) + geom_bar(stat=&quot;identity&quot;, position=&quot;dodge&quot;) + geom_errorbar(aes(ymin=value.x-value.y, ymax=value.x+value.y), position=position_dodge(0.9), width = 0.4) 이 저작물은 크리에이티브 커먼즈 저작자표시-비영리-변경금지 4.0 국제 라이선스에 따라 이용할 수 있습니다. "],
["analysis-example.html", "Chapter 6 Analysis example 6.1 ALL dataset 6.2 Heatmap with sequence data", " Chapter 6 Analysis example 6.1 ALL dataset BT 그룹별 유전자들의 발현 분포를 boxplot 이용해서 비교 library(tidyr) library(dplyr) library(tibble) library(Biobase) library(ALL) library(hgu95av2.db) library(ggplot2) data(ALL) ## data ex_data &lt;- exprs(ALL)[1:30,] ph_data &lt;- pData(ALL)[,c(&quot;cod&quot;, &quot;sex&quot;, &quot;BT&quot;)] ## remove missing | duplicated genes ph_data &lt;- ph_data[complete.cases(ph_data),] feature_names &lt;- rownames(ex_data) gene_names &lt;- unlist(as.list(hgu95av2SYMBOL[feature_names])) idx &lt;- which(is.na(gene_names) | duplicated(gene_names)) ex_data &lt;- as.data.frame(ex_data[-idx,]) rownames(ex_data) &lt;- gene_names[-idx] ex_data[1:3,1:3] ex_data_mlt &lt;- ex_data %&gt;% rownames_to_column() %&gt;% pivot_longer(-rowname) %&gt;% mutate(bt = ph_data[name,&quot;BT&quot;]) ### boxplot ex_data_mlt %&gt;% group_by(rowname) %&gt;% ggplot(aes(x=bt, y=value, group=bt)) + facet_wrap(~rowname, ncol=9, scales=&quot;free&quot;) + geom_boxplot() + theme( axis.text.x = element_text(angle = 90, size=8, hjust = 1, vjust=0.5) ) ## NA ph_data$BT tmp &lt;- ex_data %&gt;% rownames_to_column() %&gt;% pivot_longer(-rowname) ph_data[tmp$name,]$BT ex_data_mlt &lt;- ex_data %&gt;% rownames_to_column() %&gt;% pivot_longer(-rowname) %&gt;% mutate(bt = ph_data[name,&quot;BT&quot;]) %&gt;% drop_na() ex_data_mlt %&gt;% complete.cases() BT 그룹별 유전자 발현 평균 비교 ### 평균 비교 ex_summary &lt;- ex_data_mlt %&gt;% group_by(bt, rowname) %&gt;% summarize(m=mean(value)) ggplot(ex_summary, aes(x=bt, y=m, group=bt)) + facet_wrap(~rowname, ncol=9, scales=&quot;free&quot;) + geom_bar(stat=&quot;identity&quot;) + theme( axis.text.x = element_text(angle = 90, size=8, hjust = 1, vjust=0.5) ) ### scale ggplot(ex_summary, aes(x=bt, y=m, group=bt)) + facet_wrap(~rowname, ncol=9) + geom_bar(stat=&quot;identity&quot;) + theme( axis.text.x = element_text(angle = 90, size=8, hjust = 1, vjust=0.5) ) ### testing (t-test) ex_data_mlt &lt;- ex_data %&gt;% rownames_to_column() %&gt;% pivot_longer(-rowname) %&gt;% mutate(bt = ph_data[name,&quot;sex&quot;]) ex_data_mlt %&gt;% head t.test(value~bt, data=ex_data_mlt) test_results &lt;- ex_data_mlt %&gt;% group_by(rowname) %&gt;% summarize( tval=t.test(value~bt)$statistic, pval=t.test(value~bt)$p.value, ) #### test all data(ALL) ## data ex_data &lt;- exprs(ALL) ph_data &lt;- pData(ALL)[,c(&quot;cod&quot;, &quot;sex&quot;, &quot;BT&quot;)] ## remove missing | duplicated genes ph_data &lt;- ph_data[complete.cases(ph_data),] feature_names &lt;- rownames(ex_data) gene_names &lt;- unlist(as.list(hgu95av2SYMBOL[feature_names])) idx &lt;- which(is.na(gene_names) | duplicated(gene_names)) ex_data &lt;- as.data.frame(ex_data[-idx,]) rownames(ex_data) &lt;- gene_names[-idx] dim(ex_data) ex_data_mlt &lt;- ex_data %&gt;% rownames_to_column() %&gt;% pivot_longer(-rowname) %&gt;% mutate(bt = ph_data[name,&quot;sex&quot;]) %&gt;% drop_na() test_results &lt;- ex_data_mlt %&gt;% group_by(rowname) %&gt;% summarize( tval=t.test(value~bt)$statistic, pval=t.test(value~bt)$p.value, ) dim(test_results) head(test_results) sig_results &lt;- test_results %&gt;% filter(pval&lt;0.01) sel_genes &lt;- ex_data_mlt %&gt;% filter(rowname %in% sig_results$rowname) sel_genes %&gt;% group_by(rowname) %&gt;% ggplot(aes(x=bt, y=value, group=bt)) + facet_wrap(~rowname, ncol=9, scales=&quot;free&quot;) + geom_boxplot() + theme( axis.text.x = element_text(angle = 90, size=8, hjust = 1, vjust=0.5) ) BT 그룹별 유전자 발현 anova 테스트 ### testing (anova) lm(data=ex_data_mlt, formula = value~bt) ### Let&#39;s do it together! 6.2 Heatmap with sequence data https://github.com/greendaygh/KRIBBR2020/tree/master/ngs ### Code 이 저작물은 크리에이티브 커먼즈 저작자표시-비영리-변경금지 4.0 국제 라이선스에 따라 이용할 수 있습니다. "]
]
